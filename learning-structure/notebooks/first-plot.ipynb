{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73527a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#%matplotlib \n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "326c5e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e671de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4a4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "NOTEBOOK_DIR = os.path.dirname(cwd+'/')\n",
    "ROOT = os.path.dirname(NOTEBOOK_DIR)\n",
    "\n",
    "import sys\n",
    "sys.path.append(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aab01849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot import *\n",
    "from utils.tools import *\n",
    "from utils.nn import TARGET_FUNCS_DICT, LOSS_DICT\n",
    "from networks import two_layer_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d93926",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURES_DIR = os.path.join(ROOT, 'figures/2-layer/neurons_dynamic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021029e6",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5a82cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500\n",
    "input_dim = 3\n",
    "width = 1024\n",
    "bias = True\n",
    "n_steps = 1000\n",
    "base_lr = 0.01\n",
    "batch_size = None\n",
    "tgt_func_name = \"target_func\"\n",
    "\n",
    "SEED = 42\n",
    "pause = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2886934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seeds(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab360495",
   "metadata": {},
   "source": [
    "## Set up data, model, loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b30a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "X = torch.randn(size=(n_samples, input_dim), requires_grad=False)\n",
    "target_func = TARGET_FUNCS_DICT[tgt_func_name]\n",
    "y = target_func(X).reshape(len(X), 1)\n",
    "\n",
    "# network\n",
    "network = two_layer_net.TwoLayerNet(input_dim=input_dim, width=width, bias=bias)\n",
    "network.train()\n",
    "\n",
    "# loss & optimizer\n",
    "loss = LOSS_DICT['mse'](reduction='mean')\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr=width * base_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab50974",
   "metadata": {},
   "source": [
    "## Plot initial neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84d8a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "signs = network.output_layer.weight.data.detach().numpy()[0]\n",
    "init_neurons = network.input_layer.weight.data.detach().clone().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec601058",
   "metadata": {},
   "source": [
    "## Train for a few steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b0c3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if batch_size is None:\n",
    "    batch_size = n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82d97542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figsize = (8, 8)\n",
    "    # fig = plt.figure(figsize=figsize)\n",
    "    # \n",
    "    # cmpt_steps = 0\n",
    "    # batch_index = 0\n",
    "    # while cmpt_steps < 40:\n",
    "    #     with torch.no_grad():\n",
    "    #         plot_neurons_3d(fig, neurons=network.input_layer.weight.data.detach().numpy(), signs=signs)\n",
    "    #         fig_path = os.path.join(FIGURES_DIR, 'step_{}.png'.format(cmpt_steps))\n",
    "    #         plt.savefig(fig_path, bbox_inches='tight', pad_inches=0)\n",
    "    #         fig.canvas.draw()\n",
    "    #         # plt.pause(pause)\n",
    "    #         fig.canvas.flush_events()\n",
    "    # \n",
    "    #     if batch_index >= n_samples:\n",
    "    #         batch_index = 0\n",
    "    #     # batch inputs and targets\n",
    "    #     batch_x = X[batch_index: batch_index + batch_size, :]\n",
    "    #     batch_y = y[batch_index: batch_index + batch_size]\n",
    "    #     batch_index += batch_index + batch_size\n",
    "    # \n",
    "    #     # forward\n",
    "    #     y_hat = network.forward(batch_x)\n",
    "    #     loss_ = loss(y_hat, batch_y)\n",
    "    # \n",
    "    #     # backward and gradient step\n",
    "    #     print(loss_.detach().item())\n",
    "    #     loss_.backward()\n",
    "    #     optimizer.step()\n",
    "    # \n",
    "    #     cmpt_steps += 1\n",
    "    # \n",
    "    # with torch.no_grad():\n",
    "    #     plot_neurons_3d(fig, neurons=network.input_layer.weight.data.detach().numpy(), signs=signs)\n",
    "    #     fig_path = os.path.join(FIGURES_DIR, 'step_{}.png'.format(cmpt_steps))\n",
    "    #     plt.savefig(fig_path, bbox_inches='tight', pad_inches=0)\n",
    "    #     fig.canvas.draw()\n",
    "    #     # plt.pause(pause)\n",
    "    #     fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b791eae6",
   "metadata": {},
   "source": [
    "## Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09301a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.931801199913025\n",
      "1.8972053527832031\n",
      "1.8293886184692383\n",
      "1.7308306694030762\n",
      "1.6046844720840454\n",
      "1.4543958902359009\n",
      "1.2838891744613647\n",
      "1.0975967645645142\n",
      "0.9021202921867371\n",
      "0.7076408267021179\n",
      "0.5303943753242493\n",
      "0.39421045780181885\n",
      "0.3297710716724396\n",
      "0.36724331974983215\n",
      "0.5207859873771667\n",
      "0.7694721817970276\n",
      "1.0475026369094849\n",
      "1.258638858795166\n",
      "1.316781997680664\n",
      "1.1915098428726196\n",
      "0.9257789254188538\n",
      "0.6113892197608948\n",
      "0.3423992097377777\n",
      "0.178298220038414\n",
      "0.1340850442647934\n",
      "0.19156114757061005\n",
      "0.31672587990760803\n",
      "0.4735245406627655\n",
      "0.6310353875160217\n",
      "0.7661982774734497\n",
      "0.863580584526062\n",
      "0.9147735834121704\n",
      "0.9177960157394409\n",
      "0.8762627840042114\n",
      "0.7988779544830322\n",
      "0.6984812021255493\n",
      "0.5909698605537415\n",
      "0.4938192069530487\n",
      "0.4243086874485016\n",
      "0.3968871533870697\n",
      "0.4199439585208893\n",
      "0.4923133850097656\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "cmpt_steps = 0\n",
    "batch_index = 0\n",
    "while cmpt_steps < 800:\n",
    "    plot_neurons_3d(fig, neurons=network.input_layer.weight.data.detach().numpy(), signs=signs)\n",
    "    fig_path = os.path.join(FIGURES_DIR, 'bias', 'step_{}.png'.format(cmpt_steps))\n",
    "    plt.savefig(fig_path, bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    if batch_index >= n_samples:\n",
    "        batch_index = 0\n",
    "    # batch inputs and targets\n",
    "    batch_x = X[batch_index: batch_index + batch_size, :]\n",
    "    batch_y = y[batch_index: batch_index + batch_size]\n",
    "    batch_index += batch_index + batch_size\n",
    "\n",
    "    # forward\n",
    "    y_hat = network.forward(batch_x)\n",
    "    loss_ = loss(y_hat, batch_y)\n",
    "\n",
    "    # backward and gradient step\n",
    "    print(loss_.detach().item())\n",
    "    losses.append(loss_.detach().item())\n",
    "    loss_.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    cmpt_steps += 1\n",
    "    \n",
    "plot_neurons_3d(fig, neurons=network.input_layer.weight.data.detach().numpy(), signs=signs)\n",
    "fig_path = os.path.join(FIGURES_DIR, 'bias', 'step_{}.png'.format(cmpt_steps))\n",
    "plt.savefig(fig_path, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6994418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(np.arange(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f390a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
